[
    {
        "id": "43108091",
        "title": "1972 Unix V2 \"Beta\" Resurrected",
        "url": "https://www.tuhs.org/pipermail/tuhs/2025-February/031420.html",
        "hacker_news_url": "https://news.ycombinator.com/item?id=43108091",
        "points": "179 points",
        "comments": "4 hours ago",
        "content": "<title>\n1972 Unix V2 \"Beta\" Resurrected\n</title>\n\n---\n\n<article>\nTitle: [TUHS] 1972 UNIX V2 \"Beta\" Resurrected\n\nURL Source: https://www.tuhs.org/pipermail/tuhs/2025-February/031420.html\n\nMarkdown Content:\n**Yufeng Gao via TUHS** tuhs at tuhs.org  \n_Tue Feb 18 19:31:55 AEST 2025_\n\n*   Previous message (by thread): \\[TUHS\\] Unix page at the Multicians web site.\n*   Next message (by thread): \\[TUHS\\] 1972 UNIX V2 \"Beta\" Resurrected\n*   **Messages sorted by:** [\\[ date \\]](https://www.tuhs.org/pipermail/tuhs/2025-February/date.html#31420) [\\[ thread \\]](https://www.tuhs.org/pipermail/tuhs/2025-February/thread.html#31420) [\\[ subject \\]](https://www.tuhs.org/pipermail/tuhs/2025-February/subject.html#31420) [\\[ author \\]](https://www.tuhs.org/pipermail/tuhs/2025-February/author.html#31420)\n\n* * *\n\nHi everyone,\n\nFirst-time poster here. Near the end of last year, I did some forensic analysis on the DMR tapes (https://www.tuhs.org/Archive/Applications/Dennis\\_Tapes) and had some fun playing around with them. Warren forwarded a few of my emails to this list at the end of last year and the beginning of this year, but it was never my intention for him to be my messenger, so I'm posting here myself now.\n\nHere's an update on my work with the s1/s2 tapes - I've managed to get a working system out of them. The s1 tape is a UNIX INIT DECtape containing the kernel, while s2 includes most of the distribution files.\n\nThe s1 kernel is, to date, the earliest machine-readable UNIX kernel, sitting between V1 and V2. It differs from the unix-jun72 kernel in the following ways:\n\n- It supports both V1 and V2 a.outs out of the box, whereas the unmodified unix-jun72 kernel supports only V1.\n- The core size has been increased to 16 KiB (8K words), while the unmodified unix-jun72 kernel has an 8 KiB (4K word) user core.\n\nOn the other hand, its syscall table matches that of V1 and the unix-jun72 kernel, lacking all V2 syscalls. Since it aligns with V1 in terms of syscalls, has the V2 core size and can run V2 binaries, I consider it a \"V2 beta\".\n\nlogin: root\nroot\n# ls -la\ntotal   42\n 41 sdrwrw  7 root     80 Jan  1 00:02:02 .\n 41 sdrwrw  7 root     80 Jan  1 00:02:02 ..\n 43 sdrwrw  2 root    620 Jan  1 00:01:30 bin\n147 l-rwrw  1 root  16448 Jan  1 00:33:51 core\n 42 sdrwrw  2 root    250 Jan  1 00:01:51 dev\n 49 sdrwrw  2 root    110 Jan  1 00:01:55 etc\n 54 sdrwrw  2 root     50 Jan  1 00:00:52 tmp\n 55 sdrwrw  7 root     80 Jan  1 00:00:52 usr\n# ls -la usr\ntotal    8\n 55 sdrwrw  7 root     80 Jan  1 00:00:52 .\n 41 sdrwrw  7 root     80 Jan  1 00:02:02 ..\n 56 sdrwrw  2  28      60 Jan  1 00:02:22 fort\n 57 sdrwrw  2 jack     50 Jan  1 00:02:39 jack\n 58 sdrwrw  2   6      30 Jan  1 00:02:36 ken\n 59 sdrwrw  2 root    120 Jan  1 00:00:52 lib\n 60 sdrwrw  2 sys      50 Jan  1 00:02:45 sys\n142 s-rwrw  1 jack     54 Jan  1 00:52:29 x\n# ed\na\nmain() printf(\"hello world!\\\\n\");\n.\nw hello.c\n33\nq\n# cc hello.c\nI\nII\n# ls -l a.out\ntotal    3\n153 sxrwrw  1 root   1328 Jan  1 00:02:12 a.out\n# a.out\nhello world!\n#\n\nIt's somewhat picky about the environment. So far, aap's PDP-11/20 emulator (https://github.com/aap/pdp11) is the only one capable of booting the kernel. SIMH and Ersatz-11 both hang before reaching the login prompt. This makes installation from the s1/s2 tapes difficult, as aap's emulator does not support the TC11. The intended installation process involves booting from s1 and restoring files from s2.\n\nWhat I did was I extracted the files from the s1 tape and placed them on an empty RF disk, then installed the unix-jun72 kernel. After booting from the RF under SIMH, I extracted the remaining files from s2. Finally, I replaced the unix-jun72 kernel with the s1 kernel using a hex editor, resulting in an RF disk image containing only files from s1/s2. This RF image is bootable under aap's emulator but not SIMH.\n\nThe RF disk image can be downloaded from here (https://github.com/TheBrokenPipe/Research-UNIX-V2-Beta):\nDirect link - https://github.com/TheBrokenPipe/Research-UNIX-V2-Beta/raw/refs/heads/main/s1s2unix\\_rf.img\n\nInterestingly, it\n</article>\n\n---\n\n<comments>\nTitle: 1972 Unix V2 \"Beta\" Resurrected | Hacker News\n\nURL Source: https://news.ycombinator.com/item?id=43108091\n\nMarkdown Content:\n   \n1972 Unix V2 \"Beta\" Resurrected (tuhs.org) 178 points by henry_flower 4 hours ago  | hide | past | favorite | 27 comments   \n\n\n  \n\n    \n \n digitalsushi 3 hours ago   \n\n \nSpock levels of fascinating from me. I want to learn how to compile a pdp11 emulator on my mac. \n \n reply       \n \n thequux 3 hours ago   \n\n \nCompiling an emulator is quite easy: have a look at simh. It's very portable and should just work out of the box.\nOnce you've got that working, try installing a 2.11BSD distribution. It's well-documented and came after a lot of the churn in early Unix. After that, I've had great fun playing with RT-11, to the point that I've actually written some small apps on it. \n \n reply       \n \n somat 28 minutes ago   \n\n \nThe daves garage youtube has an episode where he documents the pitfalls of compiling 2bsd for a PDP-11/83. https://www.youtube.com/watch?v=IBFeM-sa2YY basically it is an art on a memory constrained system.\nWhat I found entertaining was when he was explaining how to compile the kernel, I went Oh! that's where openbsd gets it from. it is still a very similar process. \n \n reply       \n \n colechristensen 2 hours ago   \n\n \nFrom the link:\n> It's somewhat picky about the environment. So far, aap's PDP-11/20 emulator (https://github.com/aap/pdp11) is the only one capable of booting the kernel. SIMH and Ersatz-11 both hang before reaching the login prompt. This makes installation from the s1/s2 tapes difficult, as aap's emulator does not support the TC11. The intended installation process involves booting from s1 and restoring files from s2. \n \n reply       \n \n aap_ 2 hours ago   \n\n \ngood luck though. my emulator is not particularly user friendly, as in, it has no user interface. i recommend simh (although perhaps not for this thing in particular). \n \n reply       \n \n colechristensen 2 hours ago   \n\n \nSo what mechanism do you have set up to reply 4 minutes after being mentioned? :) \n \n reply       \n \n aap_ 1 hour ago   \n\n \nCompulsively checking HN i suppose :D \n \n reply       \n \n snovymgodym 3 hours ago   \n\n \nhttps://opensimh.org/\nWorks great on Apple Silicon \n \n reply       \n \n haunter 2 hours ago   \n\n \nWhat’s the difference between an emulator and a simulator in this context? \n \n reply       \n \n o11c 2 hours ago   \n\n \nIn theory, an emulator is oriented around producing a result (this may mean making acceptable compromises), whereas a simulator is oriented around inspection of state (this usually means being exact).\nIn practice the terms are often conflated. \n \n reply       \n \n bityard 2 hours ago   \n\n \nThere is LOADS of gray area, overlap, and room for one's own philosophical interpretation... But typically simulators attempt to reproduce the details of how a particular machine worked for academic or engineering purposes, while emulators are concerned mainly with only getting the desired output. (Everything else being an implementation detail.)\nE.g. since the MAME project considers itself living documentation of arcade hardware, it would be more properly classified as a simulator. While the goal of most other video game emulators is just to play the games. \n \n reply       \n \n boznz 1 hour ago   \n\n \nToo easy! Going to build one with NAND gates. \n \n reply       \n \n nonrandomstring 2 hours ago   \n\n \nYep, this is a metal-detectorists finding religious relic moment. \n \n reply       \n \n WhyNotHugo 2 hours ago   \n\n \n1328 bytes for a hello world? BLOAT! \n \n reply       \n \n ptspts 1 hour ago   \n\n \nMy https://github.com/pts/minilibc686 can do printf-hello-world on i386 in less than 1 KiB. write-hello-world is less than 170 bytes. \n \n reply       \n \n ramon156 1 hour ago   \n\n \nTime to rice my unix! \n \n reply       \n \n dataf3l 2 hours ago   \n\n \nI love this!\nfirst time I see people use 'ed' for work!!!\nI wonder who else has to deal with ed also... recently I had to connect to an ancient system where vi \n</comments>",
        "summary": "**English Version:**\n\nToday, we’re diving into a fascinating piece of computing history: the resurrection of the 1972 UNIX V2 \"Beta.\" This project, shared on the TUHS mailing list, involves forensic analysis of old DMR tapes to bring one of the earliest versions of UNIX back to life. The researcher, Yufeng Gao, successfully extracted and booted a kernel from these tapes, which sits between UNIX V1 and V2. This \"V2 Beta\" kernel supports both V1 and V2 binaries, making it a unique snapshot of early UNIX development.\n\nThe article details the technical challenges, such as the kernel being picky about the emulator environment—only a specific PDP-11/20 emulator could boot it. The researcher also shared the process of creating a bootable disk image from the tapes, which is now available for download.\n\nIn the comments, the Hacker News community is buzzing with excitement. Some users are eager to try compiling a PDP-11 emulator on their Macs, while others share resources like the SIMH emulator and 2.11BSD distributions. There’s also a philosophical discussion about the difference between emulators and simulators, with users debating the nuances of each. Overall, the thread reflects a mix of nostalgia, technical curiosity, and appreciation for preserving computing history.\n\n---\n\n**Chinese Version:**\n\n今天，我们来聊聊一个有趣的计算机历史项目：1972年的UNIX V2 \"Beta\" 版本被成功复活。这个项目在TUHS邮件列表中被分享，研究者通过对古老的DMR磁带进行取证分析，成功恢复了UNIX早期版本之一。研究者Yufeng Gao从这些磁带中提取并启动了一个内核，这个内核介于UNIX V1和V2之间。这个“V2 Beta”内核同时支持V1和V2的二进制文件，成为早期UNIX开发的独特见证。\n\n文章中详细描述了技术挑战，比如内核对模拟器环境的挑剔——只有特定的PDP-11/20模拟器能够启动它。研究者还分享了如何从磁带中创建可启动的磁盘镜像的过程，并且这个镜像现在已经可供下载。\n\n在Hacker News的评论区，大家对这个项目充满了热情。一些用户迫不及待地想在Mac上编译PDP-11模拟器，而另一些人则分享了SIMH模拟器和2.11BSD发行版等资源。还有一些用户讨论了模拟器和仿真器之间的区别，展开了关于两者细微差别的哲学讨论。总的来说，这个帖子充满了怀旧、技术好奇以及对保存计算历史的赞赏。"
    },
    {
        "id": "43105028",
        "title": "When imperfect systems are good: Bluesky's lossy timelines",
        "url": "https://jazco.dev/2025/02/19/imperfection/",
        "hacker_news_url": "https://news.ycombinator.com/item?id=43105028",
        "points": "432 points",
        "comments": "8 hours ago",
        "content": "<title>\nWhen imperfect systems are good: Bluesky's lossy timelines\n</title>\n\n---\n\n<article>\nTitle: When Imperfect Systems are Good, Actually: Bluesky’s Lossy Timelines\n\nURL Source: https://jazco.dev/2025/02/19/imperfection/\n\nPublished Time: 2025-02-19T00:00:00+00:00\n\nMarkdown Content:\n19 Feb 2025Often when designing systems, we aim for perfection in things like consistency of data, availability, latency, and more.\n\nThe hardest part of system design is that it’s difficult (if not impossible) to design systems that have perfect consistency, perfect availability, incredibly low latency, and incredibly high throughput, all at the same time.\n\nInstead, when we approach system design, it’s best to treat each of these properties as points on different axes that we balance to find the “right fit” for the application we’re supporting.\n\nI recently made some major tradeoffs in the design of [Bluesky’s](https://bsky.app/) Following Feed/Timeline to improve the performance of writes at the cost of consistency in a way that doesn’t negatively affect users but reduced P99s by over 96%.\n\nTimeline Fanout\n---------------\n\nWhen you make a post on Bluesky, your post is indexed by our systems and persisted to a database where we can fetch it to hydrate and serve in API responses.\n\nAdditionally, a reference to your post is “fanned out” to your followers so they can see it in their Timelines.\n\nThis process involves looking up all of your followers, then inserting a new row into each of their Timeline tables in reverse chronological order with a reference to your post.\n\nWhen a user loads their Timeline, we fetch a page of post references and then hydrate the posts/actors concurrently to quickly build an API response and let them see the latest content from people they follow.\n\nThe Timelines table is sharded by user. This means each user gets their own Timeline partition, randomly distributed among shards of our horizontally scalable database (ScyllaDB), replicated across multiple shards for high availability.\n\nTimelines are regularly trimmed when written to, keeping them near a target length and dropping older post references to conserve space.\n\nHot Shards in Your Area\n-----------------------\n\nBluesky currently has around [32 Million Users](https://bsky.jazco.dev/stats) and our Timelines database is broken into hundreds of shards.\n\nTo support millions of partitions on such a small number of shards, each user’s Timeline partition is colocated with tens of thousands of other users’ Timelines.\n\nUnder normal circumstances with all users behaving well, this doesn’t present a problem as the work of an individual Timeline is small enough that a shard can handle the work of tens of thousands of them without being heavily taxed.\n\nUnfortunately, with a large number of users, some of them will do abnormal things like… well… following hundreds of thousands of other users.\n\nGenerally, this can be dealt with via policy and moderation to prevent abusive users from causing outsized load on systems, but these processes take time and can be imperfect.\n\nWhen a user follows hundreds of thousands of others, their Timeline becomes hyperactive with writes and trimming occurring at massively elevated rates.\n\nThis load slows down the individual operations to the user’s Timeline, which is fine for the bad behaving user, but causes problems to the tens of thousands of other users sharing a shard with them.\n\nWe typically call this situation a “Hot Shard”: where some resident of a shard has “hot” data that is being written to or read from at much higher rates than others. Since the data on the shard is only replicated a few times, we can’t effectively leverage the horizontal scale of our database to process all this additional work.\n\nInstead, the “Hot Shard” ends up spending so much time doing work for a single partition that operations to the colocated partitions slow down as well.\n\nStacking Latencies\n------------------\n\nReturning to our Fanout process, let’s consider the case of Fanout for a user followed by 2,000,000 other users.\n\nUnder normal circumstances, writing \n</article>\n\n---\n\n<comments>\nTitle: When imperfect systems are good: Bluesky's lossy timelines | Hacker News\n\nURL Source: https://news.ycombinator.com/item?id=43105028\n\nMarkdown Content:\n   \nWhen imperfect systems are good: Bluesky's lossy timelines (jazco.dev) 431 points by cyndunlop 7 hours ago  | hide | past | favorite | 165 comments   \n\n\n  \n\n    \n \n ChuckMcM 6 hours ago   \n\n \nAs a systems enthusiast I enjoy articles like this. It is really easy to get into the mindset of \"this must be perfect\".\nIn the Blekko search engine back end we built an index that was 'eventually consistent' which allowed updates to the index to be propagated to the user facing index more quickly, at the expense that two users doing the exact same query would get slightly different results. If they kept doing those same queries they would eventually get the exact same results.\nSystems like this bring in a lot of control systems theory because they have the potential to oscillate if there is positive feedback (and in search engines that positive feedback comes from the ranker which is looking at which link you clicked and giving it a higher weight) and it is important that they not go crazy. Some of the most interesting, and most subtle, algorithm work was done keeping that system \"critically damped\" so that it would converge quickly.\nReading this description of how user's timelines are sharded and the same sorts of feedback loops (in this case 'likes' or 'reposts') sounds like a pretty interesting problem space to explore. \n \n reply       \n \n PaulHoule 5 hours ago   \n\n \nAn airline reservation system has to be perfect (no slack in today's skies), a hotel reservation can be 98% perfect so long as there is some slack and you don't mind putting somebody up in a better room than they paid for from time to time.\nA social media system doesn't need to be perfect at all. It was clear to me from the beginning that Bluesky's feeds aren't very fast, not like they are crazy slow, but if it saves money or effort it's no problem if notifications are delayed 30s. \n \n reply       \n \n darknavi 5 hours ago   \n\n \nIt's funny because from my experience airline systems are very imperfect (timing wise).\nI (unwisely) tried to purchase an Icelandair ticket via the Chase travel portal. I would get a reservation number, go buy seats on Icelandair's website, and a few days later the entire reservation would vanish into the ether. Rinse and repeat 3x.\nI can't remember the exact verbiage, but basically tickets can be \"reserved\" and \"booked\". One means the ticket is allocated, and one means the ticket is actually paid for. I eventually sat on the phone with an executive support person as they booked the ticket and got it all the way through. It turns out Chase reserves a ticket on an airline but as an SLA of ~3 days to actually pay for the ticket. Icelandair's requires a ticket to be paid with in 24 hours, so it was timing out. \n \n reply       \n \n scarface_74 26 minutes ago   \n\n \n(Replying to both you and the parent poster)\nAirlines are far from perfect. They overbook flights and sometimes have to ask people leave and pay them for the inconvenience. My wife and I once got $1000 a piece and a hotel and food voucher to volunteer to take a flight the next day on a layover in Atlanta.\nAs far as your particular situation, the number one rule of using a third party portal to book flights or hotels is - don’t.\nI understand that Iceland Air is not a transfer partner of Chase. But even in that case, I would just wait to use my points until I could use a transfer partner.\nOn the earning side if paying cash, the difference between 2x/3x points when booking directly and 5x when going through the portal just isn’t worth the risk. \n \n reply       \n \n rconti 5 hours ago   \n\n \nEspecially for a free service!\nThink about other ad-supported sites. If you're an engineer working on an ad-supported product, the perfect consistency you strive for in your code is not the product. The product is the sum of all of the content the user \n</comments>",
        "summary": "English Version:\n\nToday, let’s talk about an interesting article titled \"When Imperfect Systems are Good, Actually: Bluesky’s Lossy Timelines.\" The article explores the challenges of system design and how striving for perfection isn’t always the best approach. Instead, it’s about finding the right balance between consistency, availability, latency, and throughput.\n\nThe author shares a case study from Bluesky, a social media platform, where they made tradeoffs in the design of their Following Feed to improve performance. By reducing consistency slightly, they managed to cut down P99 latency by over 96%, without negatively impacting the user experience. The article dives into how Bluesky’s Timeline Fanout system works, where posts are distributed to followers’ timelines, and how sharding helps manage this process. However, the system faces challenges like \"Hot Shards,\" where one hyperactive user can slow down operations for thousands of others sharing the same shard.\n\nNow, let’s look at the comments. ChuckMcM, a systems enthusiast, appreciates the article and shares his experience with Blekko’s search engine, which used an \"eventually consistent\" index. PaulHoui compares the need for perfection in different systems, like airline reservations versus social media, noting that social media doesn’t need to be perfect. Darknavi shares a frustrating experience with airline reservation systems, highlighting their imperfections. Scarface74 adds that airlines often overbook flights, and using third-party portals can be risky. Rconti points out that for free, ad-supported services, perfect consistency isn’t always necessary.\n\nIn summary, the article and comments highlight that imperfect systems can still be effective, especially when the tradeoffs align with the application’s needs.\n\n---\n\nChinese Version:\n\n今天，我们来聊一篇有趣的文章，题为《当不完美的系统实际上是好系统：Bluesky的有损时间线》。这篇文章探讨了系统设计的挑战，以及追求完美并不总是最好的方法。相反，找到一致性、可用性、延迟和吞吐量之间的平衡才是关键。\n\n作者分享了Bluesky（一个社交媒体平台）的案例研究，他们在设计关注者动态时做出了权衡。通过稍微降低一致性，他们成功将P99延迟降低了96%以上，且没有对用户体验产生负面影响。文章深入探讨了Bluesky的时间线分发系统如何工作，其中帖子被分发给关注者的时间线，以及分片如何帮助管理这一过程。然而，系统也面临“热分片”的挑战，即一个过度活跃的用户可能会拖慢同一分片上数千其他用户的操作。\n\n接下来，我们看看评论部分。系统爱好者ChuckMcM欣赏这篇文章，并分享了他使用Blekko搜索引擎的经验，该系统使用了一个“最终一致”的索引。PaulHoui比较了不同系统对完美的需求，如航空公司预订与社交媒体，指出社交媒体不需要完美。Darknavi分享了他在航空公司预订系统中的糟糕经历，突出了系统的不完美。Scarface74补充说，航空公司经常超售机票，使用第三方门户可能存在风险。Rconti指出，对于免费的广告支持服务，完美的一致性并不总是必要的。\n\n总之，文章和评论表明，不完美的系统仍然可以很有效，尤其是当权衡与应用需求一致时。"
    },
    {
        "id": "43108614",
        "title": "Build your own SQLite in Rust, Part 5: Evaluating queries",
        "url": "https://blog.sylver.dev/build-your-own-sqlite-part-5-evaluating-queries",
        "hacker_news_url": "https://news.ycombinator.com/item?id=43108614",
        "points": "66 points",
        "comments": "3 hours ago",
        "content": "<title>\nBuild your own SQLite in Rust, Part 5: Evaluating queries\n</title>\n\n---\n\n<article>\nTitle: Build your own SQLite, Part 5: Evaluating queries\n\nURL Source: https://blog.sylver.dev/build-your-own-sqlite-part-5-evaluating-queries\n\nPublished Time: 2025-02-19T22:25:33.693Z\n\nMarkdown Content:\nIn the previous posts, we've explored the [SQLite file format](https://blog.sylver.dev/build-your-own-sqlite-part-1-listing-tables) and built a simple [SQL parser](https://blog.sylver.dev/build-your-own-sqlite-part-3-sql-parsing-101). It's time to put these pieces together and implement a query evaluator! In this post, we'll lay the groundwork for evaluating SQL queries and build a query evaluator that can handle basic SELECT statements. While our initial implementation won't support filtering, sorting, grouping, or joins yet, it will give us the foundation to add these features in future posts.\n\nAs usual, the complete source code for this post is available on [GitHub](https://github.com/geoffreycopin/rqlite/commit/c7dfeeea6956e209ccbd50a727c2b9352c246082).\n\n[Permalink](https://blog.sylver.dev/build-your-own-sqlite-part-5-evaluating-queries#heading-setting-up-our-test-database \"Permalink\")Setting up our test database\n-----------------------------------------------------------------------------------------------------------------------------------------------------------------\n\nBefore we can evaluate queries, we need a database to query. We'll start by creating a simple database with a single table, `table1`, with two columns, `id` and `value`:\n\n```\nsqlite3 queries_test.db\nsqlite> create table table1(id integer, value text);\nsqlite> insert into table1(id, value) values\n    ...> (1, '11'),\n    ...> (2, '12'),\n    ...> (3, '13');\nsqlite> .exit\n```\n\n⚠️ You might be tempted to use an existing SQLite database to test your queries, but keep in mind that our implementation does not support overflow pages yet, so it might not be able to read the data from your database file.\n\n* * *\n\nThis section is specific to the Rust implementation. If you're following along with another language, you can safely skip it!\n\n* * *\n\nCurrently, our pager can only be used through an exclusive mutable reference. This was fine for our initial use cases, but as we start building more complex features, maintaining this restriction will constrain our design. We'll make the pager shareable by wrapping its inner mutable fields in an `Arc<Mutex<_>>` and `Arc<RwLock<_>>`. This will allow us to effectively clone the pager and use it from multiple places without running into borrow checker issues. At this stage of the project we could have chosen to use a simple `Rc<RefCell<_>>`, but we'll eventually need to support concurrent access to the pager, so we'll use thread-safe counterparts from the start.\n\n```\n// src/pager.rs\n\n- #[derive(Debug, Clone)]\n+ #[derive(Debug)]\npub struct Pager<I: Read + Seek = std::fs::File> {\n-   input: I,\n+   input: Arc<Mutex<I>>\n    page_size: usize,\n-   pages: HashMap<usize, page::Page>,\n+   pages: Arc<RwLock<HashMap<usize, Arc<page::Page>>>>,\n}\n```\n\nThe `read_page` and `load_page` methods need to be updated accordingly:\n\n```\nimpl<I: Read + Seek> Pager<I> {\n    // [...] \n    pub fn read_page(&self, n: usize) -> anyhow::Result<Arc<page::Page>> {\n        {\n            let read_pages = self\n                .pages\n                .read()\n                .map_err(|_| anyhow!(\"failed to acquire pager read lock\"))?;\n\n            if let Some(page) = read_pages.get(&n) {\n                return Ok(page.clone());\n            }\n        }\n\n        let mut write_pages = self\n            .pages\n            .write()\n            .map_err(|_| anyhow!(\"failed to acquire pager write lock\"))?;\n\n        if let Some(page) = write_pages.get(&n) {\n            return Ok(page.clone());\n        }\n\n        let page = self.load_page(n)?;\n        write_pages.insert(n, page.clone());\n        Ok(page)\n    }\n\n    fn load_page(&self, n: usize) -> anyhow::Result<Arc<page::Page>> {\n        let offset = n.saturating_sub(1) * self.page_size;\n\n        let mut input_guard = self\n  \n</article>\n\n---\n\n<comments>\nTitle: Build your own SQLite in Rust, Part 5: Evaluating queries | Hacker News\n\nURL Source: https://news.ycombinator.com/item?id=43108614\n\nMarkdown Content:\n   \nBuild your own SQLite in Rust, Part 5: Evaluating queries (sylver.dev) 65 points by todsacerdoti 3 hours ago  | hide | past | favorite | 3 comments   \n\n\n  \n\n    \n \n bfrog 1 hour ago   \n\n \nThis is a really cool set of articles, and while it’s not going to replace sqlite it’s fantastic to see the pieces needed to do sql with SQLite’s file format \n \n reply       \n \n rockwotj 28 minutes ago   \n\n \nSQLites successor in rust is a thing though\nhttps://github.com/tursodatabase/limbo \n \n reply       \n \n MobiusHorizons 9 minutes ago   \n\n \nperhaps instead of `successor` you could say `rust fork` or `alternative`. Successor implies the original is dead or deprecated, or no longer going to be used, which is very far from the truth. \n \n reply\n\n</comments>",
        "summary": "English Version:\n\nToday, we’re diving into a fascinating article titled \"Build your own SQLite in Rust, Part 5: Evaluating queries.\" This is the fifth installment in a series where the author is building a simplified version of SQLite in Rust. In this part, the focus is on implementing a query evaluator that can handle basic SELECT statements. While the current implementation doesn’t support advanced features like filtering, sorting, or joins, it lays the groundwork for adding those in the future. The article also walks through setting up a test database and making the pager shareable in Rust using `Arc<Mutex<_>>` and `Arc<RwLock<_>>` to handle concurrent access.\n\nNow, let’s turn to the comments section. The Hacker News community has some interesting takes on this project. One user, bfrog, praises the series, calling it \"really cool\" and appreciating the insights into how SQLite’s file format works, even though it’s not meant to replace SQLite. Another user, rockwotj, mentions a Rust-based project called Limbo, which they describe as a potential \"successor\" to SQLite. However, MobiusHorizons disagrees with the term \"successor,\" suggesting it’s more accurate to call it a \"Rust fork\" or \"alternative,\" since SQLite is still very much alive and widely used.\n\n---\n\nChinese Version:\n\n今天我们来看一篇非常有趣的文章，标题是《用Rust构建你自己的SQLite，第5部分：查询评估》。这是该系列的第五部分，作者正在用Rust构建一个简化版的SQLite。在这一部分中，重点是实现一个可以处理基本SELECT语句的查询评估器。虽然目前的实现还不支持过滤、排序或连接等高级功能，但它为未来添加这些功能奠定了基础。文章还介绍了如何设置一个测试数据库，并通过使用`Arc<Mutex<_>>`和`Arc<RwLock<_>>`使Rust中的pager可共享，以处理并发访问。\n\n接下来，我们来看看评论区的讨论。Hacker News的社区对这篇文章有一些有趣的看法。用户bfrog称赞这个系列“非常酷”，并表示尽管它并不是为了取代SQLite，但能够深入了解SQLite的文件格式非常有趣。另一位用户rockwotj提到一个名为Limbo的Rust项目，将其描述为SQLite的“继任者”。然而，MobiusHorizons不同意“继任者”这个说法，认为更准确的描述应该是“Rust分支”或“替代品”，因为SQLite仍然非常活跃且广泛使用。"
    },
    {
        "id": "43096477",
        "title": "Show HN: Subtrace – Wireshark for Docker Containers",
        "url": "https://github.com/subtrace/subtrace",
        "hacker_news_url": "https://news.ycombinator.com/item?id=43096477",
        "points": "204 points",
        "comments": "9 hours ago",
        "content": "<title>\nShow HN: Subtrace – Wireshark for Docker Containers\n</title>\n\n---\n\n<article>\nTitle: GitHub - subtrace/subtrace: Wireshark for Docker containers\n\nURL Source: https://github.com/subtrace/subtrace\n\nMarkdown Content:\nGitHub - subtrace/subtrace: Wireshark for Docker containers\n===============                                         \n\n[Skip to content](https://github.com/subtrace/subtrace#start-of-content)  \n\nNavigation Menu\n---------------\n\nToggle navigation\n\n[](https://github.com/)\n\n[Sign in](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fsubtrace%2Fsubtrace)\n\n*   Product\n    \n    *   [GitHub Copilot Write better code with AI](https://github.com/features/copilot)\n    *   [Security Find and fix vulnerabilities](https://github.com/features/security)\n    *   [Actions Automate any workflow](https://github.com/features/actions)\n    *   [Codespaces Instant dev environments](https://github.com/features/codespaces)\n    *   [Issues Plan and track work](https://github.com/features/issues)\n    *   [Code Review Manage code changes](https://github.com/features/code-review)\n    *   [Discussions Collaborate outside of code](https://github.com/features/discussions)\n    *   [Code Search Find more, search less](https://github.com/features/code-search)\n    \n    Explore\n    \n    *   [All features](https://github.com/features)\n    *   [Documentation](https://docs.github.com/)\n    *   [GitHub Skills](https://skills.github.com/)\n    *   [Blog](https://github.blog/)\n    \n*   Solutions\n    \n    By company size\n    \n    *   [Enterprises](https://github.com/enterprise)\n    *   [Small and medium teams](https://github.com/team)\n    *   [Startups](https://github.com/enterprise/startups)\n    *   [Nonprofits](https://github.com/solutions/industry/nonprofits)\n    \n    By use case\n    \n    *   [DevSecOps](https://github.com/solutions/use-case/devsecops)\n    *   [DevOps](https://github.com/solutions/use-case/devops)\n    *   [CI/CD](https://github.com/solutions/use-case/ci-cd)\n    *   [View all use cases](https://github.com/solutions/use-case)\n    \n    By industry\n    \n    *   [Healthcare](https://github.com/solutions/industry/healthcare)\n    *   [Financial services](https://github.com/solutions/industry/financial-services)\n    *   [Manufacturing](https://github.com/solutions/industry/manufacturing)\n    *   [Government](https://github.com/solutions/industry/government)\n    *   [View all industries](https://github.com/solutions/industry)\n    \n    [View all solutions](https://github.com/solutions)\n    \n*   Resources\n    \n    Topics\n    \n    *   [AI](https://github.com/resources/articles/ai)\n    *   [DevOps](https://github.com/resources/articles/devops)\n    *   [Security](https://github.com/resources/articles/security)\n    *   [Software Development](https://github.com/resources/articles/software-development)\n    *   [View all](https://github.com/resources/articles)\n    \n    Explore\n    \n    *   [Learning Pathways](https://resources.github.com/learn/pathways)\n    *   [Events & Webinars](https://resources.github.com/)\n    *   [Ebooks & Whitepapers](https://github.com/resources/whitepapers)\n    *   [Customer Stories](https://github.com/customer-stories)\n    *   [Partners](https://partner.github.com/)\n    *   [Executive Insights](https://github.com/solutions/executive-insights)\n    \n*   Open Source\n    \n    *   [GitHub Sponsors Fund open source developers](https://github.com/sponsors)\n    \n    *   [The ReadME Project GitHub community articles](https://github.com/readme)\n    \n    Repositories\n    \n    *   [Topics](https://github.com/topics)\n    *   [Trending](https://github.com/trending)\n    *   [Collections](https://github.com/collections)\n    \n*   Enterprise\n    \n    *   [Enterprise platform AI-powered developer platform](https://github.com/enterprise)\n    \n    Available add-ons\n    \n    *   [Advanced Security Enterprise-grade security features](https://github.com/enterprise/advanced-security)\n    *   [GitHub Copilot Enterprise-grade AI features](https://github.com/features/copilot#enterprise)\n    *   [Premium Support Enterprise-gra\n</article>\n\n---\n\n<comments>\nTitle: Show HN: Subtrace – Wireshark for Docker Containers | Hacker News\n\nURL Source: https://news.ycombinator.com/item?id=43096477\n\nMarkdown Content:\n   \nShow HN: Subtrace – Wireshark for Docker Containers (github.com/subtrace) 204 points by adtac 9 hours ago  | hide | past | favorite | 41 comments   \nHey HN, we built Subtrace (https://subtrace.dev) to let you see all incoming and outgoing requests in your backend server—like Wireshark, but for Docker containers. It comes with a Chrome DevTools-like interface. Check out this video: https://www.youtube.com/watch?v=OsGa6ZwVxdA, and see our docs for examples: https://docs.subtrace.dev.\nSubtrace lets you see every request with full payload, headers, status code, and latency details. Tools like Sentry and OpenTelemetry often leave out these crucial details, making prod debugging slow and annoying. Most of the time, all I want to see are the headers and JSON payload of real backend requests, but it's impossible to do that in today's tools without excessive logging, which just makes everything slower and more annoying.\nSubtrace shows you every backend request flowing through your system. You can use simple filters to search for the requests you care about and inspect their details.\nInternally, Subtrace intercepts all network-related Linux syscalls using Seccomp BPF so that it can act as a proxy for all incoming and outgoing TCP connections. It then parses HTTP requests out of the proxied TCP stream and sends them to the browser over WebSocket. The Chrome DevTools Network tab is already ubiquitous for viewing HTTP requests in the frontend, so we repurposed it to work in the browser like any other app (we were surprised that it's just a bunch of TypeScript).\nSetup is just one command for any Linux program written in any language.\nYou can use Subtrace by adding a `subtrace run` prefix to your backend server startup command. No signup required. Try for yourself: https://docs.subtrace.dev \n\n\n  \n\n    \n \n qwertox 4 hours ago   \n\n \nWireshark seems a bit misleading. More like a \"network inspector\" if one leans towards the browser's network tab in the inspector?\nBut it really looks useful and I'll definitely play with it to see if I put it into my toolbox. \n \n reply       \n \n adtac 3 hours ago   \n\n \nThanks!\nre the Wireshark analogy: the reason I used that was because: (1) Subtrace operates at roughly the same level in the operating system stack, (2) has similar capabilities, (3) has an overlap in use-cases, and (4) has been the most effective at communicating what Subtrace is in my experience so far. I can see why the analogy is not a perfect 1:1 mapping (obligatory xkcd: https://xkcd.com/624), but naming things is hard and taglines are just names in idea space :) \n \n reply       \n \n jolmg 58 minutes ago   \n\n \nMy first impression with \"Wireshark for Docker containers\" is \"... Well, Wireshark already works with Docker containers, so if your goal is to be Wireshark for Docker containers, you'll just fail by definition. Can't beat Wireshark at being Wireshark.\"\nI'm saying this just FYI. I haven't actually looked at what your product does, but if it were to matter to me, it'd be based on what it can offer that Wireshark can't, rather than how similar it is to Wireshark. \n \n reply       \n \n conradev 1 hour ago   \n\n \nCan I download a pcap file? Being able to view and debug the application protocol is one thing, but I can use Wireshark to view and debug TCP itself.\nReading the documentation makes it sound like this sits one or two levels above where Wireshark usually operates, which is why I think the analogy is tough. \n \n reply       \n \n jgauth 6 hours ago   \n\n \nLooks like it is for http requests only? If so, wireshark is not an apt comparison. \n \n reply       \n \n adtac 6 hours ago   \n\n \nFor now, yes :)\nSince we operate at the TCP level, we can actually handle pretty much any protocol. I have an implementation of a postgres handler in my git stash that intercepts and shows the SQL queries executed \n</comments>",
        "summary": "The article introduces Subtrace, a tool described as \"Wireshark for Docker containers.\" Subtrace allows developers to monitor all incoming and outgoing requests in their backend servers, similar to how Wireshark captures network traffic. The tool provides a Chrome DevTools-like interface, enabling users to inspect details such as full payloads, headers, status codes, and latency. Subtrace operates by intercepting Linux syscalls using Seccomp BPF, acting as a proxy for TCP connections, and parsing HTTP requests from the proxied stream. The setup is straightforward, requiring just one command to start using it with any Linux program, regardless of the programming language.\n\n---\n\n评论部分呈现了不同的观点。一些用户认为将 Subtrace 比作 Wireshark 有些误导，因为 Subtrace 更像是一个“网络检查器”，类似于浏览器的网络标签页。另一些用户则指出，Subtrace 的功能主要集中在 HTTP 请求上，而 Wireshark 可以处理更多协议，包括 TCP 层面的调试。开发者 adtac 解释说，使用 Wireshark 的类比是为了更好地传达工具的功能和定位，尽管这并不是一个完美的 1:1 映射。还有一些用户对工具的实际功能表示好奇，比如是否支持下载 pcap 文件，以及它是否能处理除 HTTP 之外的其他协议。总体而言，评论中既有对工具实用性的期待，也有对类比准确性的讨论。\n\n---\n\n文章介绍了 Subtrace，一个被描述为“Docker 容器的 Wireshark”的工具。Subtrace 允许开发者监控其后端服务器中的所有传入和传出请求，类似于 Wireshark 捕获网络流量的方式。该工具提供了一个类似于 Chrome DevTools 的界面，使用户可以检查完整的有效载荷、头信息、状态码和延迟等细节。Subtrace 通过使用 Seccomp BPF 拦截 Linux 系统调用来工作，充当 TCP 连接的代理，并从代理的流中解析 HTTP 请求。设置非常简单，只需一个命令即可开始使用，适用于任何 Linux 程序，无论使用哪种编程语言。\n\n---\n\n评论部分展示了不同的观点。一些用户认为将 Subtrace 比作 Wireshark 有些误导，因为 Subtrace 更像是一个“网络检查器”，类似于浏览器的网络标签页。另一些用户则指出，Subtrace 的功能主要集中在 HTTP 请求上，而 Wireshark 可以处理更多协议，包括 TCP 层面的调试。开发者 adtac 解释说，使用 Wireshark 的类比是为了更好地传达工具的功能和定位，尽管这并不是一个完美的 1:1 映射。还有一些用户对工具的实际功能表示好奇，比如是否支持下载 pcap 文件，以及它是否能处理除 HTTP 之外的其他协议。总体而言，评论中既有对工具实用性的期待，也有对类比准确性的讨论。"
    },
    {
        "id": "43103073",
        "title": "Show HN: Mastra – Open-source JS agent framework, by the developers of Gatsby",
        "url": "https://github.com/mastra-ai/mastra",
        "hacker_news_url": "https://news.ycombinator.com/item?id=43103073",
        "points": "311 points",
        "comments": "9 hours ago",
        "content": "<title>\nShow HN: Mastra – Open-source JS agent framework, by the developers of Gatsby\n</title>\n\n---\n\n<article>\nTitle: GitHub - mastra-ai/mastra: the TypeScript AI agent framework\n\nURL Source: https://github.com/mastra-ai/mastra\n\nMarkdown Content:\nGitHub - mastra-ai/mastra: the TypeScript AI agent framework\n===============                                         \n\n[Skip to content](https://github.com/mastra-ai/mastra#start-of-content)  \n\nNavigation Menu\n---------------\n\nToggle navigation\n\n[](https://github.com/)\n\n[Sign in](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fmastra-ai%2Fmastra)\n\n*   Product\n    \n    *   [GitHub Copilot Write better code with AI](https://github.com/features/copilot)\n    *   [Security Find and fix vulnerabilities](https://github.com/features/security)\n    *   [Actions Automate any workflow](https://github.com/features/actions)\n    *   [Codespaces Instant dev environments](https://github.com/features/codespaces)\n    *   [Issues Plan and track work](https://github.com/features/issues)\n    *   [Code Review Manage code changes](https://github.com/features/code-review)\n    *   [Discussions Collaborate outside of code](https://github.com/features/discussions)\n    *   [Code Search Find more, search less](https://github.com/features/code-search)\n    \n    Explore\n    \n    *   [All features](https://github.com/features)\n    *   [Documentation](https://docs.github.com/)\n    *   [GitHub Skills](https://skills.github.com/)\n    *   [Blog](https://github.blog/)\n    \n*   Solutions\n    \n    By company size\n    \n    *   [Enterprises](https://github.com/enterprise)\n    *   [Small and medium teams](https://github.com/team)\n    *   [Startups](https://github.com/enterprise/startups)\n    *   [Nonprofits](https://github.com/solutions/industry/nonprofits)\n    \n    By use case\n    \n    *   [DevSecOps](https://github.com/solutions/use-case/devsecops)\n    *   [DevOps](https://github.com/solutions/use-case/devops)\n    *   [CI/CD](https://github.com/solutions/use-case/ci-cd)\n    *   [View all use cases](https://github.com/solutions/use-case)\n    \n    By industry\n    \n    *   [Healthcare](https://github.com/solutions/industry/healthcare)\n    *   [Financial services](https://github.com/solutions/industry/financial-services)\n    *   [Manufacturing](https://github.com/solutions/industry/manufacturing)\n    *   [Government](https://github.com/solutions/industry/government)\n    *   [View all industries](https://github.com/solutions/industry)\n    \n    [View all solutions](https://github.com/solutions)\n    \n*   Resources\n    \n    Topics\n    \n    *   [AI](https://github.com/resources/articles/ai)\n    *   [DevOps](https://github.com/resources/articles/devops)\n    *   [Security](https://github.com/resources/articles/security)\n    *   [Software Development](https://github.com/resources/articles/software-development)\n    *   [View all](https://github.com/resources/articles)\n    \n    Explore\n    \n    *   [Learning Pathways](https://resources.github.com/learn/pathways)\n    *   [Events & Webinars](https://resources.github.com/)\n    *   [Ebooks & Whitepapers](https://github.com/resources/whitepapers)\n    *   [Customer Stories](https://github.com/customer-stories)\n    *   [Partners](https://partner.github.com/)\n    *   [Executive Insights](https://github.com/solutions/executive-insights)\n    \n*   Open Source\n    \n    *   [GitHub Sponsors Fund open source developers](https://github.com/sponsors)\n    \n    *   [The ReadME Project GitHub community articles](https://github.com/readme)\n    \n    Repositories\n    \n    *   [Topics](https://github.com/topics)\n    *   [Trending](https://github.com/trending)\n    *   [Collections](https://github.com/collections)\n    \n*   Enterprise\n    \n    *   [Enterprise platform AI-powered developer platform](https://github.com/enterprise)\n    \n    Available add-ons\n    \n    *   [Advanced Security Enterprise-grade security features](https://github.com/enterprise/advanced-security)\n    *   [GitHub Copilot Enterprise-grade AI features](https://github.com/features/copilot#enterprise)\n    *   [Premium Support Enterprise-grad\n</article>\n\n---\n\n<comments>\nTitle: Show HN: Mastra – Open-source JS agent framework, by the developers of Gatsby | Hacker News\n\nURL Source: https://news.ycombinator.com/item?id=43103073\n\nMarkdown Content:\n   \nShow HN: Mastra – Open-source JS agent framework, by the developers of Gatsby (github.com/mastra-ai) 312 points by calcsam 9 hours ago  | hide | past | favorite | 101 comments   \nHi HN, we’re Sam, Shane, and Abhi, and we’re building Mastra (https://mastra.ai), an open-source JavaScript SDK for building agents on top of Vercel’s AI SDK.\nYou can start a Mastra project with `npm create mastra` and create workflow graphs that can suspend/resume, build a RAG pipeline and write evals, give agents memory, create multi-agent workflows, and view it all in a local playground.\nPreviously, we built Gatsby, the open-source React web framework. Later, we worked on an AI-powered CRM but it felt like we were having to roll all the AI bits (agentic workflows, evals, RAG) ourselves. We also noticed our friends building AI applications suffering from long iteration cycles: they were getting stuck debugging prompts, figuring out why their agents called (or didn’t call) tools, and writing lots of custom memory retrieval logic.\nAt some point we just looked at each other and were like, why aren't we trying to make this part easier, and decided to work on Mastra.\nDemo video: https://www.youtube.com/watch?v=8o_Ejbcw5s8\nOne thing we heard from folks is that seeing input/output of every step, of every run of every workflow, is very useful. So we took XState and built a workflow graph primitive on top with OTel tracing. We wrote the APIs to make control flow explicit: `.step()` for branching, `.then()` for chaining, and `.after()` for merging. We also added .`.suspend()/.resume()` for human-in-the-loop.\nWe abstracted the main RAG verbs like `.chunk()`, `embed()`, `.upsert(),’ `.query()`, and `rerank()` across document types and vector DBs. We shipped an eval runner with evals like completeness and relevance, plus the ability to write your own.\nThen we read the MemGPT paper and implemented agent memory on top of AI SDK with a `lastMessages` key, `topK` retrieval, and a `messageRange` for surrounding context (think `grep -C`).\nBut we still weren’t sure whether our agents were behaving as expected, so we built a local dev playground that lets you curl agents/workflows, chat with agents, view evals and traces across runs, and iterate on prompts with an assistant. The playground uses a local storage layer powered by libsql (thanks Turso team!) and runs on localhost with `npm run dev` (no Docker).\nMastra agents originally ran inside a Next.js app. But we noticed that AI teams’ development was increasingly decoupled from the rest of their organization, so we built Mastra so that you can also run it as a standalone endpoint or service.\nSome things people have been building so far: one user automates support for an iOS app he owns with tens of thousands of paying users. Another bundled Mastra inside an Electron app that ingests aerospace PDFs and outputs CAD diagrams. Another is building WhatsApp bots that let you chat with objects like your house.\nWe did (for now) adopt an Elastic v2 license. The agent space is pretty new, and we wanted to let users do whatever they want with Mastra but prevent, eg, AWS from grabbing it.\nIf you want to get started: - On npm: npm create mastra@latest - Github repo: https://github.com/mastra-ai/mastra - Demo video: https://www.youtube.com/watch?v=8o_Ejbcw5s8 - Our website homepage: https://mastra.ai (includes some nice diagrams and code samples on agents, RAG, and links to examples) - And our docs: https://mastra.ai/docs\nExcited to share Mastra with everyone here – let us know what you think! \n\n\n  \n\n    \n \n _pdp_ 3 hours ago   \n\n \nI don't want to be that person but there are hundreds of other similar frameworks doing more or less the same thing. Do you know why? Because writing a framework that orchestrates a number of tools with a model is the easy par\n</comments>",
        "summary": "English Version:\n\nToday, we’re diving into Mastra, an open-source JavaScript agent framework developed by the team behind Gatsby. Mastra is designed to simplify the process of building AI agents by providing tools for workflow management, RAG pipelines, agent memory, and more. The framework is built on top of Vercel’s AI SDK and offers features like step-by-step workflow graphs, human-in-the-loop capabilities, and a local development playground for testing and iteration.\n\nThe creators of Mastra, Sam, Shane, and Abhi, previously worked on Gatsby and later an AI-powered CRM. They noticed that many developers were struggling with long iteration cycles in AI development, such as debugging prompts, managing tool calls, and custom memory retrieval logic. Mastra aims to streamline these processes and make AI development more accessible.\n\nKey features include:\n- Workflow graphs with suspend/resume functionality.\n- RAG pipeline tools like chunking, embedding, and querying.\n- Agent memory inspired by the MemGPT paper.\n- A local dev playground for testing and prompt iteration.\n\nThe framework is available under an Elastic v2 license, allowing users to modify and use Mastra freely while preventing large corporations from exploiting it. Users have already started building diverse applications with Mastra, from automating customer support to creating WhatsApp bots.\n\nNow, let’s look at some community reactions. One commenter, _pdp_, points out that there are many similar frameworks available, suggesting that orchestrating tools with AI models is relatively easy. However, they acknowledge that Mastra’s focus on specific AI challenges may set it apart.\n\n---\n\nChinese Version:\n\n今天我们要介绍的是Mastra，一个由Gatsby团队开发的开源JavaScript代理框架。Mastra旨在简化构建AI代理的过程，提供了工作流管理、RAG管道、代理记忆等工具。该框架基于Vercel的AI SDK构建，并提供逐步工作流图、人工干预功能和本地开发环境等功能，方便测试和迭代。\n\nMastra的创始人Sam、Shane和Abhi之前曾开发过Gatsby，后来还参与了一个AI驱动的CRM项目。他们注意到许多开发者在AI开发中遇到了迭代周期长的问题，比如调试提示、管理工具调用和自定义记忆检索逻辑。Mastra的目标是简化这些流程，使AI开发更加容易。\n\n主要功能包括：\n- 支持暂停/恢复功能的工作流图。\n- RAG管道工具，如分块、嵌入和查询。\n- 受MemGPT论文启发的代理记忆功能。\n- 用于测试和提示迭代的本地开发环境。\n\n该框架采用Elastic v2许可证，允许用户自由修改和使用Mastra，同时防止大公司利用它。用户已经开始使用Mastra构建各种应用，从自动化客户支持到创建WhatsApp机器人。\n\n现在来看一下社区的反应。一位名为_pdp的用户指出，市面上有很多类似的框架，认为用AI模型协调工具相对容易。不过，他们也承认Mastra在解决特定AI挑战方面的专注可能使其与众不同。"
    },
    {
        "id": "43070558",
        "title": "The 8-Bit Era's Weird Uncle: The TI-99/4A",
        "url": "https://bumbershootsoft.wordpress.com/2025/02/15/the-8-bit-eras-weird-uncle-the-ti-99-4a/",
        "hacker_news_url": "https://news.ycombinator.com/item?id=43070558",
        "points": "45 points",
        "comments": "4 hours ago",
        "content": "<title>\nThe 8-Bit Era's Weird Uncle: The TI-99/4A\n</title>\n\n---\n\n<article>\nTitle: The 8-Bit Era’s Weird Uncle: The TI-99/4A\n\nURL Source: https://bumbershootsoft.wordpress.com/2025/02/15/the-8-bit-eras-weird-uncle-the-ti-99-4a/\n\nPublished Time: 2025-02-15T20:30:00+00:00\n\nMarkdown Content:\nIt’s been awhile since I’ve looked at an architecture that’s completely new to me, and I haven’t done _any_ since creating my new scheme for dedicated platform guides. I’ve now gotten enough material together that I can kick off an exploration of a new platform for me: the [Texas Instruments TI-99/4A](https://en.wikipedia.org/wiki/TI-99/4A). For this new introduction, I’ll be splitting it into three parts, two of which go live today:\n\n*   This article, which will be a breezy tour of interacting with the system as a casual user of the time might. This tracks my tours of the [ZX81](https://bumbershootsoft.wordpress.com/2017/02/28/the-zx81-from-the-ground-up/), the [Atari 800](https://bumbershootsoft.wordpress.com/2019/02/14/atari-800-stumbling-into-a-new-system/), and the [Amiga 500](https://bumbershootsoft.wordpress.com/2022/06/02/a-new-friend-lets-play-amiga-workbench-1-3/).\n*   The [new TI-99/4A platform guide](https://bumbershootsoft.wordpress.com/platform-guide-ti-99-4a/), as it presently exists. This page will retain my most up-to-date instructions for setting up emulation and cross-development, along with some simple test programs and an index of relevant articles.\n*   Next week’s article, which will use the tools and resources in the platform guide to see how we can realize this week’s work as cartridge software running without support from BASIC.\n\nSome History\n------------\n\nThe TI-99/4 series was released over about the same timeframe as the Atari 800 and the Commodore VIC-20, and its capabilities were comfortably intermediate between the two. Entering when it did, it ended up in a price war that ultimately locked TI into a strategy of selling the base unit at a loss, then making it up on margins on their software. In the event, they ultimately locked out all third-party software for the platform and then didn’t release all that much first-party software either. TI crashes out of the home computer market in 1984 and never returns.\n\nThis would normally result in just being another forgotten also-ran like the Timex Sinclair 2068 (a ZX Spectrum variant for the US that was basically incompatible with all ZX Spectrum software), but it’s got three things going for it as a curiosity to revisit:\n\n*   Despite being a debacle for TI, it was a debacle because it _lost them a ton of money,_ not because it wasn’t widely available and recognized. It was common enough that it still got program listings in computer magazines long after it was discontinued.\n*   The architecture of the machine is absolutely wild. We’ll see more of that next week, but for now, we’ll just note that internal pressures at TI resulted in a project that started out both as a game console in the Atari 2600 vein and as a very compact implementation of their TI-990 minicomputer line. This dual nature is clearly visible in the architecture, once we get down into it.\n*   Its game-console lineage turns out to be _really important and influential._ While the computer as a whole was an also-ran, its graphics and sound chips were sold separately for a _long_ time afterwards and were very widely used. The TI-99’s sound chip, the SN76489, was not only in the ColecoVision and the 8-bit Sega consoles, it made it all the way to the Sega Genesis (where [I actually programmed some songs into it](https://bumbershootsoft.wordpress.com/2018/03/24/genesis-the-z80-and-the-sn76489/)) and also found its way into the BBC Micro and the IBM PCjr. Its graphics chip, the TMS9918A, or its immediate successors were used in early Sega consoles (even the Sega Master System, which counts as “late” here, includes a full compatibility mode), the ColecoVision console, and the MSX hardware standard that was extremely popular outside of the US. The chip’s _design_ was also widely influen\n</article>\n\n---\n\n<comments>\nTitle: The 8-Bit Era's Weird Uncle: The TI-99/4A | Hacker News\n\nURL Source: https://news.ycombinator.com/item?id=43070558\n\nMarkdown Content:\n   \nThe 8-Bit Era's Weird Uncle: The TI-99/4A (bumbershootsoft.wordpress.com) 47 points by rbanffy 4 hours ago  | hide | past | favorite | 16 comments   \n\n\n  \n\n    \n \n geocrasher 1 hour ago   \n\n \nI'll never forget the TI-99/4A. I was 8 years old, in second grade in Southern California. We had a \"computer lab\" which was a mobile building with 13 or 15 TI-99/4A's, and about half of them had color TV's and the rest, B+W. Nobody really knew anything, but we did have books to copy BASIC programs out of.\nOne kid entered a program that flashed colors and patterns on the color TV. Our teacher was epileptic, and this sent her into a seizure. Myself and another kid ran to get the 5th grade teacher who'd been a doctor at some point (don't ask, I dont know, I was 8) and he came running and attended to her. She was fine.\nI'd always been interested in how things work, taking things apart, playing with my 30-in-1 electronics lab from Radio Shack. But this new computer thing... this was something. That experience flipped a bit in my 8 year old brain. All because of a TI-99/4A. \n \n reply       \n \n PaulHoule 2 hours ago   \n\n \nI guess next week they're going to get to the interesting bit which is how weird the architecture actually was on that thing...\nhttps://en.wikipedia.org/wiki/TI-99/4A\nParticularly it only had 256 bytes of RAM attached to the CPU but had (I think) 16 kb of RAM attached to the video controller which the CPU could read and write through I/O registers. You could use this for non-video storage but you couldn't access it directly.\nCoding in BASIC could, at the very least, hide the insanity from you. \n \n reply       \n \n phire 52 minutes ago   \n\n \nIt gets way weirder.\nThe TMS9900 didn't have any internal data registers. It only had a program counter, a status register, and a workspace pointer. Instead, it put the \"registers\" in that same 256 bytes of RAM. There were sixteen 16-bit registers which the workspace pointer pointed to.\nThe original idea was that this made for fast context switches, instead of dumping all registers to stack (it doesn't even have a stack pointer), just update the workspace pointer to point at a new set. But I have to assume this wasn't really used on the TI-99/4A, as there just wasn't enough RAM. Because your only other ram was locked behind the video controller, that 256 bytes had to contain all your registers, any your dynamically loaded code and any data you wanted rapid access to.\nThe TMS9900 is weird, because it's the only CPU of the early home computer era that wasn't designed for microcomputers. It's actually an implementation of the TI-990 mini-computer on a single chip and is actually used in later versions of the minicomputer. Those minicomputers had more than enough fast 16-bit memory to take advantage of this fast context switching.\nEvery other commonly used microprocessor of the 70s (8080, 6800, F8, 6502, RCA1802, Z80, 6809, 8086, 68000) was explicitly designed to target the low-cost microcomputer market. \n \n reply       \n \n qiqitori 56 minutes ago   \n\n \nSpeaking of interesting bits, this machine isn't actually an 8-bit computer, the CPU is 16-bit. (The video controller is 8-bit though, i.e. the VRAM data bus is 8-bits. It's also the same video controller used in various other machines, e.g. MSX.) \n \n reply       \n \n phire 32 minutes ago   \n\n \n\"Bits\" is a stupid measure of \"computer\". The TI-99/4A clearly belongs in the 8-bit era of computers.\nMotorola's 68000 was the single most prolific microprocessor of the 16-bit era. Yet all the registers are 32-bit, and all the instructions easily operate on 32-bit values [1]. About the only claim to being \"16-bit\" is the 16-bit wide data bus.\nIf we go by that metric, then the IBM PC (with its 8088 hobbled by an 8-bit data bus) is clearly just another 8-bit microcomputer.\nBTW, this is absolutely the way that Motoro\n</comments>",
        "summary": "**English Version:**\n\nToday, we’re diving into the quirky world of the TI-99/4A, a home computer from the 8-bit era that’s often overlooked but has a fascinating history. The article, titled *The 8-Bit Era’s Weird Uncle: The TI-99/4A*, takes us on a journey through the system’s unique architecture, its place in history, and its lasting influence on gaming and computing.\n\nThe TI-99/4A was released in the early 1980s, around the same time as popular systems like the Atari 800 and Commodore VIC-20. Despite its capabilities, it struggled in the market due to a price war and TI’s decision to lock out third-party software. This led to the company exiting the home computer market in 1984. However, the TI-99/4A left a mark with its unusual design, which blended elements of a game console and a minicomputer. Its graphics and sound chips, in particular, were widely used in other systems like the ColecoVision, Sega consoles, and even the BBC Micro.\n\nThe article is split into three parts: an overview of the system, a detailed platform guide for emulation and development, and a deep dive into its architecture, which will be covered next week. The author highlights the machine’s weirdness, such as its limited CPU RAM (only 256 bytes) and its reliance on video controller RAM for additional storage. This setup made programming on the TI-99/4A a unique challenge.\n\n---\n\nNow, let’s look at the comments. The Hacker News community shared some interesting stories and insights. One user, *geocrasher*, reminisced about a childhood experience with the TI-99/4A in a school computer lab, where a program triggered an epileptic seizure in their teacher. This event sparked their lifelong interest in computers. Another user, *PaulHoule*, pointed out the machine’s bizarre architecture, particularly the separation of CPU and video RAM. *Phire* added that the TI-99/4A’s CPU, the TMS9900, had no internal registers, instead using RAM for this purpose, a design choice that was unusual for the time. Finally, *qiqitori* clarified that while the TI-99/4A is often grouped with 8-bit computers, its CPU is actually 16-bit, though its video controller is 8-bit.\n\nOverall, the comments reflect a mix of nostalgia, technical curiosity, and appreciation for the TI-99/4A’s unique place in computing history.\n\n---\n\n**Chinese Version:**\n\n今天我们来看看 TI-99/4A 这个来自 8 位机时代的家用计算机。它虽然常常被忽视，但却有着一段非常有趣的历史。文章标题为《8 位机时代的“怪叔叔”：TI-99/4A》，带我们深入探讨了这款系统的独特架构、历史地位以及对游戏和计算机的持久影响。\n\nTI-99/4A 于 20 世纪 80 年代初发布，与 Atari 800 和 Commodore VIC-20 等热门系统同期上市。尽管性能不俗，但由于价格战和德州仪器（TI）决定封锁第三方软件，它在市场上举步维艰，最终导致 TI 在 1984 年退出了家用计算机市场。不过，TI-99/4A 以其独特的设计留下了深刻影响，它融合了游戏主机和微型计算机的元素。尤其是其图形和声音芯片，被广泛应用于其他系统，如 ColecoVision、世嘉游戏机甚至 BBC Micro。\n\n文章分为三部分：系统概览、详细平台指南（用于模拟和开发），以及对架构的深入探讨（将在下周发布）。作者强调了这款机器的“怪异”之处，例如其 CPU 仅有 256 字节的内存，并且依赖视频控制器的 RAM 进行额外存储。这种设计使得在 TI-99/4A 上编程成为一项独特的挑战。\n\n---\n\n接下来，我们来看看评论。Hacker News 的社区分享了一些有趣的故事和见解。一位用户 *geocrasher* 回忆了童年时在学校计算机实验室使用 TI-99/4A 的经历，当时一个程序导致他们的老师癫痫发作。这一事件激发了他对计算机的终身兴趣。另一位用户 *PaulHoule* 指出，这款机器的架构非常奇特，尤其是 CPU 和视频 RAM 的分离。*Phire* 补充说，TI-99/4A 的 CPU TMS9900 没有内部寄存器，而是使用 RAM 来实现这一功能，这种设计在当时非常罕见。最后，*qiqitori* 澄清说，虽然 TI-99/4A 常被归类为 8 位计算机，但其 CPU 实际上是 16 位的，尽管其视频控制器"
    },
    {
        "id": "43102528",
        "title": "Accelerating scientific breakthroughs with an AI co-scientist",
        "url": "https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/",
        "hacker_news_url": "https://news.ycombinator.com/item?id=43102528",
        "points": "272 points",
        "comments": "11 hours ago",
        "content": "<title>\nAccelerating scientific breakthroughs with an AI co-scientist\n</title>\n\n---\n\n<article>\nTitle: Accelerating scientific breakthroughs with an AI co-scientist\n\nURL Source: https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/\n\nMarkdown Content:\nIn the pursuit of scientific advances, researchers combine ingenuity and creativity with insight and expertise grounded in literature to generate novel and viable research directions and to guide the exploration that follows. In many fields, this presents a breadth and depth conundrum, since it is challenging to navigate the rapid growth in the rate of scientific publications while integrating insights from unfamiliar domains. Yet overcoming such challenges is critical, as evidenced by the many modern breakthroughs that have emerged from transdisciplinary endeavors. For example, Emmanuelle Charpentier and Jennifer Doudna won the [2020 Nobel Prize in Chemistry](https://www.nobelprize.org/uploads/2020/10/popular-chemistryprize2020.pdf) for their work on [CRISPR](https://en.wikipedia.org/wiki/CRISPR), which combined expertise ranging from microbiology to genetics to molecular biology.\n\nMotivated by unmet needs in the modern scientific discovery process and building on [recent AI advances](https://arxiv.org/abs/2403.05530), including the ability to synthesize across complex subjects and to perform [long-term planning and reasoning](https://deepmind.google/technologies/gemini/flash-thinking/), we developed an [AI co-scientist system](https://storage.googleapis.com/coscientist_paper/ai_coscientist.pdf). The AI co-scientist is a multi-agent AI system that is intended to function as a collaborative tool for scientists. Built on [Gemini 2.0, AI co-scientist is](https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/) designed to mirror the reasoning process underpinning the scientific method. Beyond standard literature review, summarization and “deep research” tools, the AI co-scientist system is intended to uncover new, original knowledge and to formulate demonstrably novel research hypotheses and proposals, building upon prior evidence and tailored to specific research objectives.\n\nEmpowering scientists and accelerating discoveries with the AI co-scientist\n---------------------------------------------------------------------------\n\nGiven a scientist’s research goal that has been specified in natural language, the AI co-scientist is designed to generate novel research hypotheses, a detailed research overview, and experimental protocols. To do so, it uses a coalition of specialized agents — _Generation_, _Reflection_, _Ranking_, _Evolution_, _Proximity_ and _Meta-review_ — that are inspired by the scientific method itself. These agents use automated feedback to iteratively generate, evaluate, and refine hypotheses, resulting in a self-improving cycle of increasingly high-quality and novel outputs.\n\nPurpose-built for collaboration, scientists can interact with the system in many ways, including by directly providing their own seed ideas for exploration or by providing feedback on generated outputs in natural language. The AI co-scientist also uses tools, like web-search and specialized AI models, to enhance the grounding and quality of generated hypotheses.\n\nThe AI co-scientist parses the assigned goal into a research plan configuration, managed by a Supervisor agent. The Supervisor agent assigns the specialized agents to the worker queue and allocates resources. This design enables the system to flexibly scale compute and to iteratively improve its scientific reasoning towards the specified research goal.\n\nScaling test-time compute for advanced scientific reasoning\n-----------------------------------------------------------\n\nThe AI co-scientist leverages [test-time compute](https://arxiv.org/abs/2408.03314) scaling to iteratively reason, evolve, and improve outputs. Key reasoning steps include [self-play](https://deepmind.google/discover/blog/alphago-zero-starting-from-scratch/)–based scientific debate for novel hypo\n</article>\n\n---\n\n<comments>\nTitle: Accelerating scientific breakthroughs with an AI co-scientist | Hacker News\n\nURL Source: https://news.ycombinator.com/item?id=43102528\n\nMarkdown Content:\n   \nAccelerating scientific breakthroughs with an AI co-scientist (research.google) 272 points by Jimmc414 11 hours ago  | hide | past | favorite | 131 comments   \n\n\n  \n\n    \n \n crypto420 8 hours ago   \n\n \nI'm not sure if people here even read the entirety of the article. From the article:\n> We applied the AI co-scientist to assist with the prediction of drug repurposing opportunities and, with our partners, validated predictions through computational biology, expert clinician feedback, and in vitro experiments.\n> Notably, the AI co-scientist proposed novel repurposing candidates for acute myeloid leukemia (AML). Subsequent experiments validated these proposals, confirming that the suggested drugs inhibit tumor viability at clinically relevant concentrations in multiple AML cell lines.\nand,\n> For this test, expert researchers instructed the AI co-scientist to explore a topic that had already been subject to novel discovery in their group, but had not yet been revealed in the public domain, namely, to explain how capsid-forming phage-inducible chromosomal islands (cf-PICIs) exist across multiple bacterial species. The AI co-scientist system independently proposed that cf-PICIs interact with diverse phage tails to expand their host range. This in silico discovery, which had been experimentally validated in the original novel laboratory experiments performed prior to use of the AI co-scientist system, are described in co-timed manuscripts (1, 2) with our collaborators at the Fleming Initiative and Imperial College London. This illustrates the value of the AI co-scientist system as an assistive technology, as it was able to leverage decades of research comprising all prior open access literature on this topic.\nThe model was able to come up with new scientific hypotheses that were tested to be correct in the lab, which is quite significant. \n \n reply       \n \n dekhn 6 hours ago   \n\n \nSo, I've been reading Google research papers for decades now and also worked there for a decade and wrote a few papers of my own.\nWhen google publishes papers, they tend to juice the results significance (google is not the only group that does this, but they are pretty egregious). You need to be skilled in the field of the paper to be able to pare away the exceptional claims. A really good example is https://spectrum.ieee.org/chip-design-controversy while I think Google did some interesting work there and it's true they included some of the results in their chip designs, their comparison claims are definitely over-hyped and they did not react well when they got called out on it. \n \n reply       \n \n warbaker 1 hour ago   \n\n \nThe article you linked is not an example of this happening. Google open-sourced the chip design method, and uses it in production for TPU and other chips.\nhttps://github.com/google-research/circuit_training\nhttps://deepmind.google/discover/blog/how-alphachip-transfor... \n \n reply       \n \n tsumnia 5 hours ago   \n\n \nRemember Google is a publicly traded company, so everything must be reviewed to \"ensure shareholder value\". Like dekhn said, its impressive, but marketing wants more than \"impressive\". \n \n reply       \n \n dekhn 5 hours ago   \n\n \nThis is true for public universities and private universities; you see the same thing happening in academic papers (and especially the university PR around the paper) \n \n reply       \n \n hall0ween 5 hours ago   \n\n \nI would say anecdotal. This hasn't been my case across four universities and ten years. \n \n reply       \n \n BeetleB 4 hours ago   \n\n \nThe actual papers don't overhype. But the university PR's regarding those papers? They can really overhype the results. And of course, the media then takes it up an extra order of magnitude. \n \n reply       \n \n nyrikki 1 hour ago   \n\n \nDepends on what you call \"overhype\".\nWishful mnemonics in the \n</comments>",
        "summary": "English Version:\n\nToday, let’s talk about an exciting development in scientific research: the AI co-scientist. This system, developed by Google, aims to accelerate scientific breakthroughs by assisting researchers in generating novel hypotheses and research plans. The AI co-scientist is built on Gemini 2.0 and is designed to mimic the scientific method, going beyond standard literature reviews to uncover new knowledge and propose original research ideas. It uses specialized agents like Generation, Reflection, and Ranking to iteratively refine hypotheses, creating a self-improving cycle of high-quality outputs. The system can also scale its computational resources to enhance scientific reasoning, making it a powerful tool for researchers.\n\nNow, let’s dive into the comments. One user, crypto420, highlights the practical applications of the AI co-scientist, citing examples where it successfully proposed drug repurposing candidates and explained complex biological phenomena. However, dekhn, a former Google employee, cautions about Google’s tendency to overhype research results. He points out that while Google’s work is impressive, claims often need to be critically evaluated by experts in the field. Other users, like warbaker and tsumnia, add that Google’s public status and marketing goals can influence how research is presented. Meanwhile, BeetleB notes that while academic papers may not overhype, the surrounding PR and media coverage often exaggerate findings. Finally, nyrikki brings up the issue of “wishful mnemonics,” suggesting that even the terminology used in research can sometimes be misleading.\n\n---\n\nChinese Version:\n\n今天，我们来聊聊科学界的一项激动人心的进展：AI合作科学家。这个由谷歌开发的系统，旨在通过协助研究人员生成新颖的假设和研究计划，加速科学突破。AI合作科学家基于Gemini 2.0构建，旨在模仿科学方法，超越标准的文献综述，发现新知识并提出原创的研究思路。它使用生成、反思和排名等专门的代理，迭代地优化假设，创建一个自我改进的高质量输出循环。该系统还可以扩展其计算资源，以增强科学推理能力，使其成为研究人员的强大工具。\n\n现在，我们来看看评论。用户crypto420强调了AI合作科学家的实际应用，举例说明了它成功提出了药物重新利用的候选方案，并解释了复杂的生物现象。然而，前谷歌员工dekhn提醒大家，谷歌倾向于夸大研究成果。他指出，尽管谷歌的工作令人印象深刻，但往往需要该领域的专家对声明进行严格评估。其他用户如warbaker和tsumnia补充说，谷歌的公众地位和营销目标可能会影响研究结果的呈现方式。与此同时，BeetleB指出，虽然学术论文可能不会夸大其词，但围绕它们的公关和媒体报道往往会夸大事实。最后，nyrikki提出了“愿望助记符”的问题，表明研究中使用的术语有时也可能具有误导性。"
    },
    {
        "id": "43109860",
        "title": "Corvus Robotics (YC S18) Is Hiring Senior Software Engineer",
        "url": "https://app.dover.com/apply/269adc8b-72b8-46d3-85b9-3a15ea901c84/eaf81e6d-73d3-4fcf-b273-7772720503c2/",
        "hacker_news_url": "https://news.ycombinator.com/item?id=43109860",
        "points": "0 points",
        "comments": "48 minutes ago",
        "content": "<title>\nCorvus Robotics (YC S18) Is Hiring Senior Software Engineer\n</title>\n\n---\n\n<article>\nTitle: Dover\n\nURL Source: https://app.dover.com/apply/269adc8b-72b8-46d3-85b9-3a15ea901c84/eaf81e6d-73d3-4fcf-b273-7772720503c2/\n\nMarkdown Content:\nDover\n===============\n\n</article>\n\n---\n\n<comments>\nTitle: Corvus Robotics (YC S18) Is Hiring Senior Software Engineer | Hacker News\n\nURL Source: https://news.ycombinator.com/item?id=43109860\n\nMarkdown Content:\n[Corvus Robotics (YC S18) Is Hiring Senior Software Engineer](https://app.dover.com/apply/269adc8b-72b8-46d3-85b9-3a15ea901c84/eaf81e6d-73d3-4fcf-b273-7772720503c2/) ([dover.com](https://news.ycombinator.com/from?site=dover.com))\n\n[20 minutes ago](https://news.ycombinator.com/item?id=43109860) | [hide](https://news.ycombinator.com/hide?id=43109860&goto=item%3Fid%3D43109860)\n\n</comments>",
        "summary": "English Version:\n\nToday, we’re discussing a job posting from Corvus Robotics, a company that was part of Y Combinator’s Summer 2018 batch. They’re currently hiring for a Senior Software Engineer position, and the job is listed on Dover, a platform for job applications.\n\nLet’s dive into the comments section to see what people are saying. Unfortunately, there aren’t any comments on this post yet. This could be because the post is relatively new, or perhaps people haven’t had the chance to share their thoughts. If you’re interested in learning more about the role or Corvus Robotics, you can check out the job listing directly on Dover.\n\n---\n\nChinese Version:\n\n今天，我们讨论的是来自Corvus Robotics的招聘信息，这家公司是Y Combinator 2018年夏季批次的一部分。他们目前正在招聘一名高级软件工程师，职位发布在Dover这个求职平台上。\n\n让我们来看看评论区里的讨论。遗憾的是，这篇帖子目前还没有任何评论。这可能是因为帖子比较新，或者大家还没有机会分享他们的看法。如果你对这个职位或者Corvus Robotics感兴趣，可以直接在Dover上查看招聘信息。"
    },
    {
        "id": "43101383",
        "title": "Broken legs and ankles heal better if you walk on them within weeks",
        "url": "https://www.scientificamerican.com/article/broken-legs-and-ankles-heal-better-if-you-walk-on-them-within-weeks/",
        "hacker_news_url": "https://news.ycombinator.com/item?id=43101383",
        "points": "328 points",
        "comments": "13 hours ago",
        "content": "<title>\nBroken legs and ankles heal better if you walk on them within weeks\n</title>\n\n---\n\n<article>\nTitle: Broken Legs and Ankles Heal Better If You Walk on Them within Weeks\n\nURL Source: https://www.scientificamerican.com/article/broken-legs-and-ankles-heal-better-if-you-walk-on-them-within-weeks/\n\nPublished Time: 2025-02-18T09:00:00-05:00\n\nMarkdown Content:\nFebruary 18, 2025\n\n4 min read\n\nUsing crutches for months is largely a thing of the past. Early weight-bearing has real benefits\n\nJay Bendt\n\nTwenty years ago my husband, Mark, broke his left ankle and was in a cast and on crutches for nearly two months. Last year he broke the other ankle. But this time, after surgery, his doctor surprised us by instructing Mark to walk on it two weeks later.\n\nIt turns out the standard advice to stay off a broken leg bone for at least six weeks is based less on scientific evidence and more on cultural caution—physicians like to play it safe. But now studies show that complications are no more likely with early weight-bearing than with a long delay. Except in a few complex cases, walking around earlier helps broken bones heal, and it improves quality of life: for example, people can return to work and other activities faster.\n\nIf you are fully immobilized, “you come out of the cast with a sort of hairy, withered leg that takes forever to overcome,” says orthopedic trauma surgeon Alex Trompeter of St. George’s University of London. “The science tells us that the rate at which you lose muscle mass is far faster than the rate at which you gain it.” You’re slow to build bone, too. Consider astronauts. After six months in zero gravity at the International Space Station, they lose 10 percent of their bone density, and to ward off that loss they do exercises in space that are equivalent to bearing weight.\n\n* * *\n\nOn supporting science journalism\n--------------------------------\n\nIf you're enjoying this article, consider supporting our award-winning journalism by [subscribing](https://www.scientificamerican.com/getsciam/). By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.\n\n* * *\n\nIn the 19th century German surgeon and anatomist Julius Wolff recognized that healthy bones adapt and change in response to the load placed on them. That is why everyone—but especially women, who are more susceptible than men to osteoporosis—should lift weights as they age. It increases bone density.\n\n> Those who walked early on femurs that had broken just above the knee had no higher rate of complications than those who stayed off the leg for six weeks.\n\nWhen you fracture a bone anywhere in the body, physicians first worry about stability. How much will the bone fragments move if you put weight on them? If the answer is too much, surgery is usually indicated—first a “reduction” to realign the pieces of bone and then “fixation” to hold them in place with screws, plates or rods.\n\nThat procedure sets up a bone, which is living tissue, to heal naturally by making new bone and resorbing damaged cells. In the gap caused by a fracture, a healing tissue called callus forms first, which then turns into bone. The right amount of load or movement (here’s where Wolff’s discovery applies) is critical to this process. Too little results in no callus; too much prevents the bone from knitting back together. “It’s all about the strain environment,” says orthopedic surgeon Chris Bretherton of Queen Mary’s Hospital in London.\n\nSurgical implants hold the alignment until that process is complete. “It’s a little bit of a race postoperatively between the bone healing and the fixation breaking,” says orthopedic trauma surgeon Marilyn Heng of the University of Miami Miller School of Medicine. In that contest, she roots for the new bone. “Once the body heals and forms bone across the fracture site, the hardware we put in becomes extraneous. The crux of our decisions for weight-bearing status is we want to win that race.”\n\nAnd putting some load on the bones aids that goal. Although the process of bone hea\n</article>\n\n---\n\n<comments>\nTitle: Broken legs and ankles heal better if you walk on them within weeks | Hacker News\n\nURL Source: https://news.ycombinator.com/item?id=43101383\n\nMarkdown Content:\n   \nBroken legs and ankles heal better if you walk on them within weeks (scientificamerican.com) 317 points by sohkamyung 12 hours ago  | hide | past | favorite | 203 comments   \n\n\n  \n\n    \n \n ehnto 11 hours ago   \n\n \nThe pathology for broken collar bones was changing right as I took up mountain biking, and subsequently shattered my collarbone.\nIt was hotly debated at the hospital, if my specific case should be operated on or not. Each time I had a checkup, one doctor would say \"wait and see\" while the other was saying \"I can't believe we didn't operate on this\".\nAt any rate, the outcome was as good as if they had operated on it, according to the doc anyway. Nice of them to test it out on me!\nMore related to this though, I have broken both my collarbones, the first time I had little direction and just held my arm still for 2-3 months. It took forever to heal, and my arm atrophied significantly. The second time, similar severity. I was guided through rehab and I was back using my arm within the first month, very little atrophy. \n \n reply       \n \n jack_pp 9 hours ago   \n\n \nI had a broken collar bone last year in Bucharest and I moved back to my hometown because of it. I had to check in after a week or two to see how it's healing but was lazy about it so I went to the hospital after 3 weeks and was told there's a waiting list 10 days long and go to a private clinic. At the private clinic the doctor didn't even look at me, or the x-rays I just took and just told me to go into surgery back in Bucharest. Luckily when my mother heard she found a surgeon through a friend of a friend that looked at my x-rays on whatsapp and told me it's fine but just to be sure to visit him in Bucharest feel it in person, which the private care doctor never did.\nSo after 4 weeks I went to this last guy in a public hospital, told me I'm fine and can take off my brace, wait a week or two and go into physical therapy. Also told me in 20 years he only had to once or twice do a collar bone surgery so it's almost never the answer.\nIt's amazing that just being told I'm fine I could relax and all my muscle aches literally were gone 1 hour after that meeting so my advice in general is, be very careful what doctor you choose because medical hexing really is a thing. We put doctors on this pedestal and if God forbid you catch them in a bad mood they can fuck you up worse than before you saw them. \n \n reply       \n \n pkulak 27 minutes ago   \n\n \nI've still never heard a satisfactory explanation for how in the hell two parts of a bone, broken such that they aren't even touching, can find their way back to each other and heal. My son broke his collar bone, and the hospital sent him home in a sling. When I looked at the x-ray, I couldn't believe that's the correct treatment. But a month or two later and he was good as new. Absolutely blows my mind every time I think of it. \n \n reply       \n \n jamiedumont 8 hours ago   \n\n \nI shattered my collarbone - and I do mean shattered, ~8 pieces - in a mountain bike crash September 2023. I went over the bars after the back wheel of my hardtail caught a berm. Landed on my head and shoulder and compressed it laterally inwards by about 2 inches.\nEven with this mess, it was hotly debated for around two weeks whether I needed surgery. A good chunk of my collarbone was trying to push through my skin and the other half was fusing to my scapular and was starting to compromise nerve function. Even then, because the non-surgical route is now considered the standard, I was meeting resistance to have an ORIF. It seems that the about turn from surgical intervention has been so strong that getting ANY surgical intervention is a battle.\nI eventually came across a surgeon who took one look at me (never mind the imaging) and scheduled me for surgery. ~18 months later I’m now on a w\n</comments>",
        "summary": "---\n\n**English Version:**\n\nToday, we’re diving into an article from Scientific American titled *\"Broken Legs and Ankles Heal Better If You Walk on Them within Weeks.\"* The article challenges the traditional advice of staying off a broken leg or ankle for extended periods, suggesting that early weight-bearing can actually speed up recovery and improve quality of life.\n\nThe key takeaway is that immobilizing a broken bone for too long can lead to muscle atrophy and slower bone regeneration. Studies show that walking on a broken bone within weeks—when medically appropriate—doesn’t increase the risk of complications and can help the bone heal faster. This approach is supported by the concept of Wolff’s Law, which states that bones adapt to the loads placed on them. Surgeons now emphasize the importance of balancing stability and movement to encourage natural bone healing.\n\nNow, let’s look at the comments from Hacker News. Users shared personal experiences with broken bones, particularly collarbones, which echoed the article’s findings. One user, ehnto, shared how rehab guidance during their second collarbone fracture led to faster recovery compared to their first injury, where they immobilized the arm for months. Another user, jack_pp, highlighted the importance of finding the right doctor, as their experience varied drastically depending on the medical advice they received. Lastly, pkulak expressed amazement at how bones can heal even when the broken pieces aren’t touching, a phenomenon that still lacks a clear explanation.\n\nOverall, the discussion underscores the evolving nature of medical advice and the importance of personalized care in recovery.\n\n---\n\n**Chinese Version:**\n\n今天，我们来聊聊《科学美国人》上的一篇文章，标题是《在几周内行走有助于骨折的腿和脚踝更快愈合》。这篇文章挑战了传统的建议，即骨折后长时间避免负重，相反，它提出早期负重实际上可以加速康复并提高生活质量。\n\n文章的核心观点是，骨折部位长时间固定会导致肌肉萎缩和骨再生变慢。研究表明，在医学允许的情况下，骨折后几周内行走并不会增加并发症的风险，反而有助于骨折更快愈合。这一观点得到了沃尔夫定律的支持，该定律指出骨骼会根据所承受的负荷进行适应性调整。如今，外科医生强调在稳定性和活动之间找到平衡，以促进骨骼的自然愈合。\n\n接下来，我们来看看Hacker News上的评论。用户们分享了他们骨折的个人经历，尤其是锁骨骨折，这些经历与文章的观点不谋而合。用户ehnto分享说，在他们第二次锁骨骨折时，康复指导让他们比第一次骨折时恢复得更快，而第一次他们固定手臂长达数月。另一位用户jack_pp强调了找到合适的医生的重要性，因为他们在不同医生的建议下经历了截然不同的治疗过程。最后，用户pkulak对骨骼即使断裂部分不接触也能愈合的现象表示惊叹，这一现象至今仍缺乏明确的解释。\n\n总的来说，这次讨论凸显了医学建议的不断演变，以及个性化护理在康复中的重要性。"
    },
    {
        "id": "43109366",
        "title": "Scented products cause indoor air pollution on par with car exhaust",
        "url": "https://newatlas.com/environment/indoor-air-pollution-scented-terpenes/",
        "hacker_news_url": "https://news.ycombinator.com/item?id=43109366",
        "points": "67 points",
        "comments": "1 hour ago",
        "content": "<title>\nScented products cause indoor air pollution on par with car exhaust\n</title>\n\n---\n\n<article>\nTitle: Scented products cause indoor air pollution on par with car exhaust\n\nURL Source: https://newatlas.com/environment/indoor-air-pollution-scented-terpenes/\n\nPublished Time: 2025-02-17T05:17:03.570Z\n\nMarkdown Content:\nScented products cause indoor air pollution on par with car exhaust\n===============\n                                                      \n\n*   [SUBSCRIBE AD-FREE](https://newatlas.com/subscribe/)\n    \n*   [LOG IN](https://newatlas.com/login/?sourceUrl=https%3A%2F%2Fnewatlas.com%2Fenvironment%2Findoor-air-pollution-scented-terpenes%2F)\n    \n\n*   [HOME](https://newatlas.com/)\n    \n*   [SCIENCE](https://newatlas.com/science/)\n    \n    *   [Biology](https://newatlas.com/biology/)\n    *   [Environment](https://newatlas.com/environment/)\n    *   [Materials](https://newatlas.com/materials/)\n    *   [Medical](https://newatlas.com/medical/)\n    *   [Physics](https://newatlas.com/physics/)\n    *   [Space](https://newatlas.com/space/)\n    *   [View all SCIENCE news](https://newatlas.com/science/)\n    \n    *   [Biology](https://newatlas.com/biology/)\n    *   [Environment](https://newatlas.com/environment/)\n    *   [Materials](https://newatlas.com/materials/)\n    *   [Medical](https://newatlas.com/medical/)\n    *   [Physics](https://newatlas.com/physics/)\n    *   [Space](https://newatlas.com/space/)\n    *   [View all SCIENCE news](https://newatlas.com/science/)\n    \n*   [TECH](https://newatlas.com/technology/)\n    \n    *   [AI & Humanoids](https://newatlas.com/ai-humanoids/)\n    *   [Consumer Tech](https://newatlas.com/consumer-tech/)\n    *   [Energy](https://newatlas.com/energy/)\n    *   [Manufacturing](https://newatlas.com/manufacturing/)\n    *   [Military](https://newatlas.com/military/)\n    *   [Robotics](https://newatlas.com/robotics/)\n    *   [Deals](https://newatlas.com/deals/)\n    *   [View all TECHNOLOGY news](https://newatlas.com/technology/)\n    \n    *   [AI & Humanoids](https://newatlas.com/ai-humanoids/)\n    *   [Consumer Tech](https://newatlas.com/consumer-tech/)\n    *   [Energy](https://newatlas.com/energy/)\n    *   [Manufacturing](https://newatlas.com/manufacturing/)\n    *   [Military](https://newatlas.com/military/)\n    *   [Robotics](https://newatlas.com/robotics/)\n    *   [Deals](https://newatlas.com/deals/)\n    *   [View all TECHNOLOGY news](https://newatlas.com/technology/)\n    \n*   [TRANSPORT](https://newatlas.com/transport/)\n    \n    *   [Aircraft](https://newatlas.com/aircraft/)\n    *   [Automotive](https://newatlas.com/automotive/)\n    *   [Bicycles](https://newatlas.com/bicycles/)\n    *   [Marine](https://newatlas.com/marine/)\n    *   [Motorcycles](https://newatlas.com/motorcycles/)\n    *   [Urban Transport](https://newatlas.com/urban-transport/)\n    *   [View all TRANSPORT news](https://newatlas.com/transport/)\n    \n    *   [Aircraft](https://newatlas.com/aircraft/)\n    *   [Automotive](https://newatlas.com/automotive/)\n    *   [Bicycles](https://newatlas.com/bicycles/)\n    *   [Marine](https://newatlas.com/marine/)\n    *   [Motorcycles](https://newatlas.com/motorcycles/)\n    *   [Urban Transport](https://newatlas.com/urban-transport/)\n    *   [View all TRANSPORT news](https://newatlas.com/transport/)\n    \n*   [LIFESTYLE](https://newatlas.com/lifestyle/)\n    \n    *   [Outdoors](https://newatlas.com/outdoors/)\n    *   [Tiny Houses](https://newatlas.com/tiny-houses/)\n    *   [Architecture](https://newatlas.com/architecture/)\n    *   [Good Thinking](https://newatlas.com/good-thinking/)\n    *   [Holiday Destinations](https://newatlas.com/holiday-destinations/)\n    *   [View all LIFESTYLE news](https://newatlas.com/lifestyle/)\n    \n    *   [Outdoors](https://newatlas.com/outdoors/)\n    *   [Tiny Houses](https://newatlas.com/tiny-houses/)\n    *   [Architecture](https://newatlas.com/architecture/)\n    *   [Good Thinking](https://newatlas.com/good-thinking/)\n    *   [Holiday Destinations](https://newatlas.com/holiday-destinations/)\n    *   [View all LIFESTYLE news](https://newatlas.com/lifestyle/)\n    \n\n</article>\n\n---\n\n<comments>\nTitle: Scented products cause indoor air pollution on par with car exhaust | Hacker News\n\nURL Source: https://news.ycombinator.com/item?id=43109366\n\nMarkdown Content:\n   \nScented products cause indoor air pollution on par with car exhaust (newatlas.com) 68 points by clumsysmurf 2 hours ago  | hide | past | favorite | 25 comments   \n\n\n  \n\n    \n \n jmward01 34 minutes ago   \n\n \nThe challenge with any article like this is that the correlated impact on health outcomes is always implied in the article but is rarely studied as part of the research cited. Just because a is bad and b has a property similar to a that doesn't imply b has the same harmful impacts as a. I really wish articles would limit big headlines like this unless the research cited was directly comparing mortality and health outcomes directly. If the study this article was based on came to the conclusion that 'average household aerosol use has a similar associated mortality risk as average city car pollution' then the title could have been warranted but instead we got a bit of click-bait. A slightly better title could have been 'Scented products cause unexpected levels of indoor air pollution'. I'd even argue 'Scented products cause concerning levels of indoor air pollution' is a reasonable title since it is worth our concern and further study. \n \n reply       \n \n 7thaccount 24 minutes ago   \n\n \nNot much to add here other than as someone with terrible allergies and asthma, the constant need for plugin air fresheners, scented candles, scented laundry detergent, and scented lotions, perfumes, febreeze, and scented deodorant drives me crazy. I don't think normal folks realize how they're breathing in straight chemicals all day. \n \n reply       \n \n xnx 1 hour ago   \n\n \nOn average, we inhale 20 lbs of air per day. This is greater by weight than the food or water we consume in a day. We should be paying a lot more attention to air quality. \n \n reply       \n \n BugsJustFindMe 1 hour ago   \n\n \nIDK, as an American I eat a lot of food. \n \n reply       \n \n protocolture 18 minutes ago   \n\n \nI didnt think americans had invented food yet. \n \n reply        \n worik 59 minutes ago   \n\n [flagged] \n \n       \n \n MathMonkeyMan 18 minutes ago   \n\n \nA rule of thumb is that if you paid sales tax for it, it's probably not food.\nOf course \"not food\" is mostly fine. \n \n reply       \n \n zdragnar 6 minutes ago   \n\n \nNot a great rule of thumb as every state and municipality is different in this regard.\nMany places will have different rates for raw food, prepared to go / delivery, and prepared for on-site consumption.\nhttps://www.cpapracticeadvisor.com/2024/08/26/109453/109453/ \n \n reply       \n \n jameshart 8 minutes ago   \n\n \nEverything in New Hampshire is food \n \n reply       \n \n kevin_thibedeau 12 minutes ago   \n\n \nSome states tax all food. \n \n reply       \n \n drusenko 47 minutes ago   \n\n \nI am having a hard time reconciling the claim in the post headline with common sense.\nOne frustrating aspect to the study is that it was hard to determine whether they are comparing like for like per unit time. They say the “operation of a gas stove” and “running a generator” — but for how long? It doesn’t seem like they tested each of these things under similar conditions in their lab but rather relied on other studies for that data. Figure 2(b) right does seem to measure this but they haven’t labeled the chart with clear labels and the description is a bit ambiguous.\nAfter reading the study, I think the issue is that the claim it is making is slightly different than the one in the headline. They are measuring VOC and ~PM2.5 pollutants, but gas engines (and gas stoves presumably as well) produce other pollutants like CO, which is what kills you of you run a gas generator indoors. \n \n reply       \n \n Havoc 43 minutes ago   \n\n \nIt’s likely selective factors being measured but on some metric the top engines produce outputs cleaner than air going in so I don’t think it’s all that improbable \n \n reply       \n \n tim\n</comments>",
        "summary": "The article titled \"Scented products cause indoor air pollution on par with car exhaust\" discusses a study that reveals how scented products, such as air fresheners, candles, and cleaning supplies, can significantly degrade indoor air quality. The research highlights that these products release volatile organic compounds (VOCs) and other pollutants, which can reach levels comparable to those produced by car exhaust. This raises concerns about the long-term health impacts of prolonged exposure to such indoor air pollution.\n\nThe article emphasizes that while the focus on outdoor air pollution is common, indoor air quality is often overlooked, despite people spending a majority of their time indoors. The findings call for greater awareness and regulation of the chemicals used in everyday scented products.\n\n---\n\nThe comments section on Hacker News reflects a mix of skepticism, concern, and humor. Some users, like jmward01, criticize the article for its clickbait headline, arguing that the study doesn’t directly link scented products to health outcomes like mortality. They suggest a more measured title that highlights the need for further research.\n\nOthers, like 7thaccount, share personal experiences with allergies and asthma, expressing frustration over the widespread use of scented products and their impact on sensitive individuals. Meanwhile, xnx points out the importance of air quality, noting that we inhale more air by weight than we consume food or water daily.\n\nThere’s also a thread of humor, with comments like BugsJustFindMe joking about Americans’ eating habits, and protocolture adding a sarcastic remark about food. However, drusenko raises a valid concern about the study’s methodology, questioning whether the comparisons between scented products and car exhaust are truly like-for-like.\n\nOverall, the comments highlight a range of perspectives, from calling for clearer scientific communication to sharing personal anecdotes and poking fun at the discussion.\n\n---\n\n这篇文章题为“香氛产品导致的室内空气污染与汽车尾气相当”，探讨了一项研究，揭示了香氛产品如空气清新剂、香薰蜡烛和清洁用品会显著降低室内空气质量。研究表明，这些产品会释放挥发性有机化合物（VOCs）和其他污染物，其浓度可与汽车尾气相媲美。这引发了人们对长期暴露于此类室内空气污染的健康影响的担忧。\n\n文章强调，虽然人们通常关注室外空气污染，但室内空气质量却常常被忽视，尽管人们大部分时间都在室内度过。研究结果呼吁人们提高对日常香氛产品中使用的化学物质的认识，并加强相关监管。\n\n---\n\nHacker News的评论区反映了质疑、担忧和幽默的混合情绪。一些用户，如jmward01，批评文章的标题有“标题党”之嫌，认为研究并未直接将香氛产品与健康结果（如死亡率）联系起来。他们建议采用更谨慎的标题，强调需要进一步研究。\n\n其他用户，如7thaccount，则分享了他们过敏和哮喘的个人经历，对香氛产品的广泛使用及其对敏感人群的影响表示不满。与此同时，xnx指出空气质量的重要性，强调我们每天吸入的空气重量超过了食物和水的摄入量。\n\n评论区还出现了一些幽默内容，如BugsJustFindMe开玩笑说美国人的饮食习惯，而protocolture则对食物发表了讽刺性评论。不过，drusenko对研究方法提出了质疑，认为香氛产品与汽车尾气的比较可能并非完全对等。\n\n总体而言，评论展示了多种观点，从呼吁更清晰的科学沟通，到分享个人经历，再到对讨论的幽默调侃。"
    }
]